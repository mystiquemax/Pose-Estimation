{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointcloud shifthing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After estimating the pose of the ArUco tag and transforming the coordinates from the CAD model's coordinate system (i.e., the demonstrator) to the scan's coordinate system (i.e., the point cloud), I noticed an issue with the depth estimation of the MechMind scanner. This observation stems from the fact that the point cloud and the CAD model (i.e., the demonstrator) are not perfectly (or nearly perfectly) aligned. To address this, I decided to find the nearest point in the point cloud to the corresponding ArUco tag on the CAD model and shift the point cloud by the distance between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Txt](images/one.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I define the depth directions of the ArUco tags e.g. ArUco tags 5 and 8 have their depth directions along the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import detect\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# ArUco size in meter:  0.105\n",
    "# 0,0,0 means the back of the arUco points to the floor and the Kosy of the Demostrator \n",
    "\n",
    "depth_directions_of_arucos = {\"x\": [5,8],\n",
    "                              \"y\": [1,2,3,4,6,7,10], \n",
    "                              \"z\": [9]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I defined some functions to load the CAD-model, the point cloud and the image taken from the camera (the camera makes a point cloud and an image simultaniously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAD-model\n",
    "def get_mesh(path): \n",
    "    mesh = o3d.io.read_triangle_mesh(path)\n",
    "    mesh.compute_vertex_normals()\n",
    "    return mesh\n",
    "\n",
    "# Pointcloud\n",
    "def get_path_to_pcd(path_to_scan):\n",
    "    return glob.glob(path_to_scan + '*.ply')[0]\n",
    "\n",
    "def get_pointcloud(path):\n",
    "    point_cloud = o3d.io.read_point_cloud(path)\n",
    "    return point_cloud\n",
    "\n",
    "# Image\n",
    "def get_path_to_image(path_to_scan):\n",
    "    return glob.glob(path_to_scan + '*.png')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that finds the nearest point from the point cloud to the center of the given ArUco (which is placed on the CAD-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_point_in_direction(pcd, reference_point, direction_vector):\n",
    "    \"\"\"\n",
    "    Get the point that is nearest to the 'reference_point' in the pointcloud in the given direction\n",
    "\n",
    "    Args: pcd = pointcloud from which we take the points\n",
    "          reference point = the starting point from which we measure the direction\n",
    "          direction_vector = the direction in which we will search the point\n",
    "    Return: nearest point to the reference point   \n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize the direction vector (# in our case the vector is already normalized. this is for any case if we use some other direction thats not on the axis (e.g if the demostrator was hexagonal prism)\n",
    "    direction_unit = direction_vector / np.linalg.norm(direction_vector)\n",
    "    \n",
    "    # Calculate the vector from the center of the Aruco to each point in the point cloud\n",
    "    vectors_to_points = np.asarray(pcd.points) - reference_point\n",
    "    \n",
    "    # Project these vectors onto the direction unit vector\n",
    "    projections = np.dot(vectors_to_points, direction_unit)\n",
    "    \n",
    "    # Calculate the distances from the projected points to the original points and find the eucliand distance to the point\n",
    "    distances = np.linalg.norm(vectors_to_points - np.outer(projections, direction_unit), axis=1)\n",
    "    \n",
    "    # Find the index of the nearest point based on the minimum distance\n",
    "    nearest_index = np.argmin(distances)\n",
    "    \n",
    "    # Get the nearest point\n",
    "    nearest_point = pcd.points[nearest_index]\n",
    "    \n",
    "    return nearest_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each possible depth direction, I defined a function. Each function iterates through the detected ArUco markers, and if it finds an ArUco with the corresponding depth direction, it retrieves its coordinates from the CAD model. It then identifies the nearest point in the point cloud along the specified direction and calculates a translation vector. The function computes the mean translation vector from all the translation vectors of the detected ArUco markers in the given image and shifts the point cloud accordingly.\n",
    "\n",
    "The specified regions of the code aren't a general solution. We know beforehand were we placed the ArUco tags and we know where the point cloud is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_translation_vector_y(pcd, ids):\n",
    "    divide = 0\n",
    "\n",
    "    mean_translation_vector_y = np.array([.0, .0, .0])\n",
    "   \n",
    "    for i in ids.flatten():\n",
    "      if i in depth_directions_of_arucos[\"y\"]:\n",
    "         with open('tag_info.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            translation = data[\"AruCo-Tag-Positionen (Tag-Mitte)\"][str(i)]\n",
    "            translation = np.array([translation])\n",
    "            aruco_center = o3d.geometry.PointCloud()\n",
    "            aruco_center.points = o3d.utility.Vector3dVector(translation)\n",
    "            direction_vector = [.0, 1.0, .0]\n",
    "            nearest_point = find_nearest_point_in_direction(pcd, translation, direction_vector)\n",
    "            ####################\n",
    "            # All arUco tags with depth direction y-axis are only on the left side of the demonstrator.\n",
    "            # That's why this is enough.\n",
    "            shift_distance = np.abs(translation[0][1] - nearest_point[1])\n",
    "            ####################\n",
    "            translation_vector = np.array([.0, shift_distance, .0])\n",
    "            print(\"ArUco Tag number: \" + str(i) + \" with depth direction in y axis\")\n",
    "            print(\"Translation vector of the give ArUco Tag\",translation_vector)\n",
    "            mean_translation_vector_y += translation_vector\n",
    "            divide+=1\n",
    "\n",
    "    if divide != 0:\n",
    "       mean_translation_vector_y /= divide\n",
    "\n",
    "    return mean_translation_vector_y   \n",
    "\n",
    "def get_mean_translation_vector_x(pcd,ids):  \n",
    "    divide = 0  \n",
    "    \n",
    "    mean_translation_vector_x = np.array([.0, .0, .0])\n",
    "\n",
    "    for i in ids.flatten():\n",
    "      if i in depth_directions_of_arucos[\"x\"]:\n",
    "         with open('tag_info.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            translation = data[\"AruCo-Tag-Positionen (Tag-Mitte)\"][str(i)]\n",
    "            translation = np.array([translation])\n",
    "            aruco_center = o3d.geometry.PointCloud()\n",
    "            aruco_center.points = o3d.utility.Vector3dVector(translation)\n",
    "            direction_vector = [1.0, .0, .0]\n",
    "            nearest_point = find_nearest_point_in_direction(pcd, translation, direction_vector)\n",
    "            ####################\n",
    "            # We have arUco tag only on the front size of the demonstrator.\n",
    "            # That's why this is enought.\n",
    "            shift_distance = translation[0][0] - nearest_point[0]\n",
    "            ####################\n",
    "            translation_vector = np.array([shift_distance, .0, .0])\n",
    "            print(\"ArUco Tag number: \" + str(i) + \" with depth direction in x axis\")\n",
    "            print(\"Translation vector of the give ArUco Tag\",translation_vector)\n",
    "            mean_translation_vector_x += translation_vector\n",
    "            divide+=1\n",
    "\n",
    "    if divide != 0:\n",
    "       mean_translation_vector_x /= divide\n",
    "\n",
    "    return mean_translation_vector_x   \n",
    "\n",
    "def get_mean_translation_vector_z(pcd,ids):  \n",
    "    divide = 0  \n",
    "    \n",
    "    mean_translation_vector_z = np.array([.0, .0, .0])\n",
    "\n",
    "    for i in ids.flatten():\n",
    "      if i in depth_directions_of_arucos[\"z\"]:\n",
    "         with open('tag_info.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            translation = data[\"AruCo-Tag-Positionen (Tag-Mitte)\"][str(i)]\n",
    "            translation = np.array([translation])\n",
    "            aruco_center = o3d.geometry.PointCloud()\n",
    "            aruco_center.points = o3d.utility.Vector3dVector(translation)\n",
    "            direction_vector = [.0, .0, 1.0]\n",
    "            nearest_point = find_nearest_point_in_direction(pcd, translation, direction_vector)\n",
    "            ####################\n",
    "            # We have only one arUco at the top of the demonstrator.\n",
    "            # That's why this is enough.\n",
    "            shift_distance = translation[0][2] - nearest_point[2]\n",
    "            ####################\n",
    "            translation_vector = np.array([.0, .0, shift_distance])\n",
    "            print(\"ArUco Tag number: \" + str(i) + \" with depth direction in z axis\")\n",
    "            print(\"Translation vector of the give ArUco Tag\", translation_vector)\n",
    "            mean_translation_vector_z += translation_vector\n",
    "            divide+=1\n",
    "\n",
    "    if divide != 0:\n",
    "       mean_translation_vector_z /= divide\n",
    "\n",
    "    return mean_translation_vector_z    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example demonstrating the code's usage and showcasing the obtained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected ArUcos in the image: [5 8 9]\n",
      "ArUco Tag number: 5 with depth direction in x axis\n",
      "Translation vector of the give ArUco Tag [-0.03372341  0.          0.        ]\n",
      "ArUco Tag number: 8 with depth direction in x axis\n",
      "Translation vector of the give ArUco Tag [-0.02429521  0.          0.        ]\n",
      "ArUco Tag number: 9 with depth direction in z axis\n",
      "Translation vector of the give ArUco Tag [ 0.          0.         -0.00407399]\n",
      "Mean translation vector: [-0.02900931  0.         -0.00407399]\n"
     ]
    }
   ],
   "source": [
    "path_to_mesh = \"data/demonstrator_model/scaled_demonstrator.stl\"\n",
    "path_to_pcd = \"data/scans_roughly_aligned/10_Mean.ply\"\n",
    "path_to_image = \"data/Mech_Eye/2024-01-19/10/\"\n",
    "\n",
    "# load the CAD-file\n",
    "mesh = get_mesh(path_to_mesh)\n",
    "# load the point cloud\n",
    "pcd = get_pointcloud(path_to_pcd)\n",
    "  \n",
    "image = cv2.imread(get_path_to_image(path_to_image))\n",
    "corners, ids, _ = detect.detect_all_markers(image, \"DICT_4X4_100\")\n",
    "print(\"Detected ArUcos in the image:\", ids.flatten())\n",
    "    \n",
    "mean_translation_vector = get_mean_translation_vector_x(pcd, ids) + get_mean_translation_vector_y(pcd, ids) + get_mean_translation_vector_z(pcd,ids)\n",
    "print(\"Mean translation vector:\", mean_translation_vector)\n",
    "pcd = pcd.translate(mean_translation_vector)\n",
    "\n",
    "pcd_original = get_pointcloud(path_to_pcd)   \n",
    "o3d.visualization.draw_geometries([mesh, pcd_original], window_name=\"Demostrator and Pointcloud Mean\", width=800, height=600) \n",
    "o3d.visualization.draw_geometries([mesh, pcd], window_name=\"Demostrator and Pointcloud\", width=800, height=600)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Text](images/two.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the achieved results are good, another issue was identified. Due to the depth estimation problem of the scanner, not only is shifting required, but also rotation, as the left side of the demonstrator is closer to the camera than the right side."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
