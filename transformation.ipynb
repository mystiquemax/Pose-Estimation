{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose estimation of an object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the ArUcos on the object (the demonstrator), I transform the demonstrator to the coordinate system of the point cloud (i.e scan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TXT](images/three.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I define helper function to load the CAD-model of the demonstrator and the point cloud. At the beginning, I saw that the CAD-model and the point cloud aren't in the same scale. I decide to downscale the mesh and than to apply the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('./')\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import detect\n",
    "import glob\n",
    "from scipy.spatial.transform import Rotation  \n",
    "\n",
    "# Mesh\n",
    "def get_mesh(path):\n",
    "    mesh = o3d.io.read_triangle_mesh(path)\n",
    "    mesh.compute_vertex_normals() \n",
    "    mesh.scale(0.01, center=(0, 0, 0))\n",
    "    return mesh\n",
    "\n",
    "# Point cloud  \n",
    "def get_pointcloud(path, downsample=False):\n",
    "    pcd = o3d.io.read_point_cloud(path)\n",
    "\n",
    "    if downsample:\n",
    "        pcd = pcd.voxel_down_sample(voxel_size=0.05)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a single detected ArUco tag in the image, I transform the demonstrator to the coordinate system of the point cloud. First, I use the position of the ArUco tag on the demonstrator (in the demonstrator's coordinate system) to create a transformation matrix from the demonstrator's coordinate system to the coordinate system of the individual ArUco tag. Next, I estimate the poses of the ArUco tags from the captured images and create a transformation matrix from the coordinate system of the ArUco tag to the coordinate system of the camera. Since the camera and the point cloud share the same coordinate system, this completes the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform point cloud based on one arUco marker\n",
    "def transform_pcd(pcd, id, path_image):\n",
    "    # Get transformation matrix from Aruco marker coordinate system to Demonstrator coordinate system\n",
    "    path_markers = \"/data/markers/ID\" \n",
    "    path_matrix = path_markers + str(id) + \".npy\"\n",
    "    T_D_A = np.load(path_matrix) ## Matrix that transforms vector / coordinates from demonstrator co. sy. to aruco co. sy.\n",
    "\n",
    "    # The scan (i.e. point cloud) and the camera are in the same coordinate system\n",
    "    T_Cam_Scan = np.eye(4)\n",
    "\n",
    "    # Get rotation matrix and translation vector of Aruco marker relative to the RGB camera\n",
    "    arucos = detect.get_marker_poses(image_path = path_image,\n",
    "                                     tag_type=\"DICT_4X4_100\",\n",
    "                                     show=False)\n",
    "    for aruco in arucos:\n",
    "        if aruco['id'] == id:\n",
    "            rotM, jac = cv2.Rodrigues(aruco['rvec'][0][0])\n",
    "            tvec = aruco['tvec'][0][0]\n",
    "            any = True\n",
    "\n",
    "    # If the arUco is on the image taken by the camera\n",
    "    if any:\n",
    "        # Tvec is translation of Aruco marker relative to the RGB camera, we need it the other way round \n",
    "        tvec = np.array(tvec)\n",
    "        tvec = -np.transpose(rotM).dot(tvec) #  i.e cameraPosition = -np.matrix(rotM).T * np.matrix(tvec)\n",
    "\n",
    "        # Merge transponed rotation matrix and tvec to transformation matrix \n",
    "        T_A_Cam = np.eye(4)\n",
    "        T_A_Cam[:3, :3] = np.transpose(np.array(rotM))\n",
    "        T_A_Cam[:3, 3] = np.array(tvec)\n",
    "\n",
    "        # Get complete transformation Demonstrator --> ArUco marker --> RGB camera --> Scan (i.e point cloud)\n",
    "        transM = T_D_A @ T_A_Cam @ T_Cam_Scan # Takes the coordinates of a vector in demostrator coordinate system and transforms them in scan (pointcloud) coordinate system\n",
    "\n",
    "        # Apply transformation matrix\n",
    "        pcd = pcd.rotate(transM[:3, :3], center=(0, 0, 0))\n",
    "        pcd = pcd.translate(transM[:3, 3])\n",
    "\n",
    "        return pcd\n",
    "    \n",
    "    else:\n",
    "        return 'ArUco marker with ID {id} not on image'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I do the same, but the transformation matrix from the demonstrator coordinate system to the scan coordinate system is based on all detected ArUcos tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_transformation_matrix_of_detected_arUcos(path_image, ids):\n",
    "\n",
    "    path_markers = \"data/markers/ID\"   \n",
    "   \n",
    "    T_Cam_Scan = np.eye(4) \n",
    "\n",
    "    # Get pose of all arucos on image\n",
    "    rotations = []\n",
    "    translations = []\n",
    "    arucos = detect.get_marker_poses(image_path = path_image,\n",
    "                           tag_type=\"DICT_4X4_100\",\n",
    "                           show=False)\n",
    "\n",
    "    for aruco in arucos:\n",
    "        if aruco['id'] in ids:\n",
    "            id = aruco['id']\n",
    "            rotM, jac = cv2.Rodrigues(aruco['rvec'].flatten())\n",
    "            tvec = aruco['tvec'].flatten()\n",
    "\n",
    "            # Get transformation matrix D (Demostrator) to given arUco-Tag (Ai)\n",
    "            path_matrix = path_markers + str(id) + \".npy\"\n",
    "            T_D_Ai = np.load(path_matrix) \n",
    "\n",
    "            # Tvec translates from Aruco CoSy to Camera CoSy, we need it the other way round\n",
    "            tvec = np.array(tvec)\n",
    "            tvec = -np.transpose(rotM).dot(tvec)\n",
    "\n",
    "            # Merge transponed rotation matrix and tvec to transformation matrix\n",
    "            T_Ai_Cam = np.eye(4)\n",
    "            T_Ai_Cam[:3, :3] = np.transpose(np.array(rotM))\n",
    "            T_Ai_Cam[:3, 3] = np.array(tvec)\n",
    "\n",
    "            # Get complete transformation Demonstrator --> ArUco marker --> RGB camera --> Scan (i.e point cloud)\n",
    "            transM = T_D_Ai @ T_Ai_Cam @ T_Cam_Scan\n",
    "\n",
    "            # Get rotation in Euler and translation for building the mean\n",
    "            rotVector = Rotation.from_matrix(transM[:3,:3]) # rotation vector from rotation marix\n",
    "            rotations.append(rotVector.as_euler('xyz', degrees=True))\n",
    "            translations.append(np.array(transM[:3, 3]))\n",
    "\n",
    "    # Calculate mean of all rotations and translations and transform back to matrix\n",
    "    rotArray = np.array(rotations).T\n",
    "    transArray = np.array(translations).T\n",
    "    mean_rot = np.mean(rotArray, axis=1)\n",
    "    mean_trans = np.mean(transArray, axis=1)\n",
    "\n",
    "    r = Rotation.from_euler(\"xyz\", mean_rot, degrees=True)\n",
    "    transM[:3, :3] = r.as_matrix()\n",
    "    transM[:3, 3] = mean_trans\n",
    "    return transM\n",
    "\n",
    "def get_mean_ply(pcd, path_image, ids):\n",
    "    transM = get_mean_transformation_matrix_of_detected_arUcos(path_image, ids)\n",
    "    pcd.transform(transM)\n",
    "    \n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function that controls the code above. Through it, one can decide to run either transform base on one ArUco or based on all ArUcos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(path_scan, id, mode):\n",
    "    # Get pointcloud and image path from scan path\n",
    "    path_mesh = 'data/demonstrator_model/demonstrator_gesamt.stl'\n",
    "\n",
    "    path_image = glob.glob(path_scan + '*.png')[0]\n",
    "\n",
    "    path_pcd = glob.glob(path_scan + '*.ply')[0]\n",
    "    \n",
    "    path_save = \"data/pointclouds_transformed/\"\n",
    "    folder_scan = os.path.basename(os.path.normpath(path_scan))\n",
    "\n",
    "    # Import mesh and pointcloud\n",
    "    mesh = get_mesh(path_mesh)\n",
    "    pcd = get_pointcloud(path_pcd)\n",
    "    # Visualize the original pcd and the mesh\n",
    "    o3d.visualization.draw_geometries([mesh, pcd])\n",
    "    \n",
    "    # Calculate and add transformation on pointcloud from a single aruco\n",
    "    if mode.lower() == \"single\":\n",
    "        pcd_new = transform_pcd(pcd, id, path_image)\n",
    "        if pcd_new != 'ID not on image':\n",
    "            o3d.io.write_point_cloud(path_save + folder_scan + \"_ID\" + str(id) + \".ply\", pcd_new)\n",
    "\n",
    "    # Using the mean value of the positions of all the arUcos        \n",
    "    elif mode.lower() == \"mean\":\n",
    "        pcd_new = get_mean_ply(pcd, path_image, ids=id)\n",
    "        o3d.io.write_point_cloud(path_save + folder_scan + \"_Mean.ply\", pcd_new)\n",
    "    \n",
    "    # Plot mesh, pointcloud and additional points/lines\n",
    "    if pcd_new != 'ID not on image': \n",
    "        mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n",
    "                        size=0.5, origin=[0, 0, 0])\n",
    "        o3d.visualization.draw_geometries([mesh, pcd_new, mesh_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example demonstrating the code's usage and showcasing the obtained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"data/Mech_Eye/2024-01-22/\"\n",
    "\n",
    "mode = \"mean\"\n",
    "\n",
    "# right side arUcos\n",
    "id = [5, 6, 7, 8]\n",
    "\n",
    "folders = os.listdir(path_prefix)\n",
    "\n",
    "for folder in folders:\n",
    "    path_scan_folder = path_prefix + f\"{folder}/\"\n",
    "    visualize(path_scan_folder, id, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![txt](images/four.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
